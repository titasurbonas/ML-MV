{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5830, 4096)\n",
      "-------\n",
      "(5830,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "Train = genfromtxt('./Train/trainVectors.csv', delimiter=',')\n",
    "Train = Train.transpose()\n",
    "\n",
    "Labels= genfromtxt('./Train/trainLbls.csv')\n",
    "\n",
    "Validate = genfromtxt('./Validation/valVectors.csv', delimiter=',')\n",
    "Validate = Validate.transpose()\n",
    "\n",
    "Vlabels= genfromtxt('./Validation/valLbls.csv')\n",
    "\n",
    "\n",
    "print(Train.shape)\n",
    "print(\"-------\")\n",
    "print(Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    5.789 0.    ... 0.    0.    0.   ]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.permutation(len(Train))\n",
    "x,y = Train[idx], Labels[idx]\n",
    "\n",
    "\n",
    "print(Train[0])\n",
    "print(Labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_390 to have shape (30,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-a59692c3058d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mmodel6Layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MSE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mmodel6Layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mValidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mVlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\titas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\titas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\titas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_390 to have shape (30,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "model6Layer = Sequential()\n",
    "\n",
    "#model6Layer.add(Flatten())\n",
    "\n",
    "model6Layer.add(Dense(input_shape = (4096,), units = 256 , activation='relu',use_bias=True, kernel_initializer='uniform'))\n",
    "\n",
    "model6Layer.add(Dense(units = 1024, activation='relu',use_bias=True, kernel_initializer='uniform'))\n",
    "\n",
    "model6Layer.add(Dense(units = 512, activation='relu', use_bias=True,kernel_initializer='uniform'))\n",
    "\n",
    "model6Layer.add(Dense(units = 265, activation='relu', use_bias=True,kernel_initializer='uniform'))\n",
    "\n",
    "model6Layer.add(Dense(units = 128, activation='relu', use_bias=True,kernel_initializer='uniform'))\n",
    "\n",
    "model6Layer.add(Dense(units = 64, activation='relu', use_bias=True,kernel_initializer='uniform'))\n",
    "\n",
    "model6Layer.add(Dense(units = 30, activation='softmax',use_bias=True, kernel_initializer='uniform'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model6Layer.compile(optimizer=sgd, loss=losses.mean_squared_error, metrics=['MSE'])\n",
    "\n",
    "model6Layer.fit(x,y ,validation_data=(Validate,Vlabels),epochs=10, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5830 samples, validate on 2298 samples\n",
      "Epoch 1/1\n",
      "5830/5830 [==============================] - 24s 4ms/step - loss: 1.4929 - acc: 0.4940 - val_loss: 1.3584 - val_acc: 0.5836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ff93f2af60>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Dense(input_shape = (4096,), units = 256 , activation=None,use_bias=True, kernel_initializer='uniform'))\n",
    "\n",
    "model.add(Dense(units = 2048, activation='relu',use_bias=True, kernel_initializer='uniform'))\n",
    "\n",
    "model.add(Dense(units = 1024, activation='relu', use_bias=True,kernel_initializer='uniform'))\n",
    "\n",
    "model.add(Dense(units = 512, activation='relu', use_bias=True,kernel_initializer='uniform'))\n",
    "\n",
    "model.add(Dense(units = 256, activation='relu', use_bias=True,kernel_initializer='uniform'))\n",
    "\n",
    "\n",
    "model.add(Dense(units = 40, activation='sigmoid',use_bias=True, kernel_initializer='uniform'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(Train,Labels ,validation_data=(Validate,Vlabels),epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6827676240208878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "nnc = KNeighborsClassifier(n_neighbors=5)\n",
    "nnc.fit(Train, Labels) \n",
    "print(nnc.score(Validate, Vlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCCres = nnc.predict_proba(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2298/2298 [==============================] - 1s 237us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4780645560906038, 0.6436031332370817]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validate = genfromtxt('./Validation/valVectors.csv', delimiter=',')\n",
    "\n",
    "Vlabels= genfromtxt('./Validation/valLbls.csv')\n",
    "Validate = Validate.transpose()\n",
    "\n",
    "model.evaluate(Validate, Vlabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = genfromtxt('./Test/testVectors.csv', delimiter=',')\n",
    "Test = Test.transpose()\n",
    "result = model.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(NCCres[1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('results.csv', mode='w') as results_file:\n",
    "    results_file = csv.writer(results_file, delimiter=',',lineterminator='\\n', quotechar='\"')\n",
    "    results_file.writerow([\"ID\",\"Label\"])\n",
    "    i = 1\n",
    "    for x in result:\n",
    "        results_file.writerow([i,np.argmax(x)])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('NCCres.csv', mode='w') as results_file:\n",
    "    results_file = csv.writer(results_file, delimiter=',',lineterminator='\\n', quotechar='\"')\n",
    "    results_file.writerow([\"ID\",\"Label\"])\n",
    "    i = 1\n",
    "    for x in NCCres:\n",
    "        results_file.writerow([i,np.argmax(x)+1])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
